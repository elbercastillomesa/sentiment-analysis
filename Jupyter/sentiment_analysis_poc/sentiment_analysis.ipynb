{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install requests\n",
    "%pip install transformers\n",
    "%pip install scipy\n",
    "%pip install 'transformers[torch]'\n",
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "%pip install wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping TikTok Comments\n",
    "\n",
    "1. Select a video\n",
    "2. Find the XHR api request using the browser development tools\n",
    "3. Imitate a request from the browser (use the headers provided by the browser, prefered Chrome)\n",
    "4. Make the request and convert data to JSON format\n",
    "5. Parse the data to make it readable\n",
    "6. Loop through the pages and save all comments\n",
    "\n",
    "Resources: \n",
    "https://www.youtube.com/watch?v=Tqnuhaaw738"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json\n",
    "import time\n",
    "import os\n",
    "\n",
    "class TitkTokCommentScraper:\n",
    "    \"\"\"\n",
    "    A class for scraping comments from TikTok videos.    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.headers = {\n",
    "            \"accept\": \"*/*\",\n",
    "            \"accept-language\": \"es-ES,es;q=0.8,en-US;q=0.5,en;q=0.3\",\n",
    "            \"cache-control\": \"no-cache\",\n",
    "            \"pragma\": \"no-cache\",\n",
    "            \"priority\": \"u=1, i\",\n",
    "            \"Referer\": \"https://www.tiktok.com/explore\",\n",
    "            \"sec-ch-ua\": '\"Google Chrome\";v=\"129\", \"Chromium\";v=\"129\", \"Not=A?Brand\";v=\"8\"',\n",
    "            \"sec-ch-ua-mobile\": \"?0\",\n",
    "            \"sec-ch-ua-platform\": '\"Windows\"',\n",
    "            \"sec-fetch-dest\": \"empty\",\n",
    "            \"sec-fetch-mode\": \"cors\",\n",
    "            \"sec-fetch-site\": \"same-origin\", \n",
    "            \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Safari/537.36\",\n",
    "        }\n",
    "\n",
    "    def _req(self, post_id : str, page_number : int = 0) -> dict:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            post_id (str): The ID of the TikTok video.\n",
    "            page_number (int, optional): The page number of comments to retrieve. Defaults to 0.\n",
    "            \n",
    "        Returns:\n",
    "            dict: A dictionary containing the json response.\n",
    "        \"\"\"\n",
    "\n",
    "        timestamp = int(time.time())\n",
    "        request_url = f\"https://www.tiktok.com/api/comment/list/?WebIdLastTime={timestamp}&aid=1988&app_language=en&app_name=tiktok_web&aweme_id={post_id}&browser_language=en-US&browser_name=Mozilla&browser_online=true&browser_platform=Win32&browser_version=5.0%20%28Windows%20NT%2010.0%3B%20Win64%3B%20x64%29%20AppleWebKit%2F537.36%20%28KHTML%2C%20like%20Gecko%29%20Chrome%2F130.0.0.0%20Safari%2F537.36&channel=tiktok_web&cookie_enabled=true&count=20&cursor={page_number}&data_collection_enabled=false&device_id=7433621668948149766&device_platform=web_pc&focus_state=true&from_page=video&history_len=2&is_fullscreen=false&is_page_visible=true&odinId=7433621429462483973&os=windows&priority_region=&referer=&region=CO&screen_height=1080&screen_width=1920&tz_name=America%2FBogota&user_is_login=false&webcast_language=en&msToken=av6rBVq946q396gSsl28RTeNIUmHRmyh119dQRpJtEMHOOq2rgFPrl2gEauidZ7zCfjoh9P5PZ11FBS6sMQRg84JTh67SECufY32cARpgbp-DjPSWUt14aoeEih-J9fxjtpF4H38743oXcMlg8JHKA==&X-Bogus=DFSzswVYCD2ANapNtsxp9V6HQhO3&_signature=_02B4Z6wo00001HlBmxQAAIDBG-6YjndyIWR5QZ-AAHmB61\"\n",
    "        \n",
    "        response = requests.get(request_url, headers=self.headers)\n",
    "        info = response.text\n",
    "        raw_data = json.loads(info)\n",
    "        \n",
    "        return raw_data\n",
    "        \n",
    "    def _parser(self, data : dict) -> list:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data (dict): A dictionary containing the json response.\n",
    "            \n",
    "        Returns:\n",
    "            list: A list of dictionaries containing the comments.\n",
    "        \"\"\"\n",
    "        \n",
    "        comments = []\n",
    "        \n",
    "        for comment in data['comments']:\n",
    "            desc_comment = comment.get('share_info', {}).get('desc', None)\n",
    "            text_comment = comment.get('text', None)        \n",
    "            user_id = comment.get('user', {}).get('unique_id', None)\n",
    "            \n",
    "            comments.append({\n",
    "                \"id\": user_id,\n",
    "                \"comment\": desc_comment,\n",
    "                \"text\": text_comment\n",
    "            })\n",
    "            \n",
    "        return comments\n",
    "    \n",
    "    def get_comments(self, post_url : str, start_page_number : int = 0, file_path : str = '') -> str:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            post_url (str): The URL of the TikTok video.\n",
    "            start_page_number (int, optional): The start page number of comments to retrieve. Defaults to 0.\n",
    "            file_path (str, optional): The path to save the comments. Defaults to '' (current directory).\n",
    "            \n",
    "        Returns:\n",
    "            str: The path to the JSON file containing the list of dictionaries with comments.\n",
    "        \"\"\"\n",
    "\n",
    "        comments = []\n",
    "        page_number = start_page_number * 20 # Default page number skips every 20 comments\n",
    "        post_id = post_url.split(\"/\")[-1]\n",
    "        file_path = os.path.join(file_path, f\"comments_for_{post_id}.json\")\n",
    "\n",
    "        while 1:\n",
    "            raw_data = self._req(post_id, page_number)\n",
    "            comments.extend(self._parser(raw_data))\n",
    "            more_data = raw_data.get('has_more', False)\n",
    "\n",
    "            if more_data == 1:\n",
    "                time.sleep(1)\n",
    "                page_number += 20\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "        with open(f\"comments_for_{post_id}.json\", \"a\", encoding=\"utf-8\") as file_path:\n",
    "            json.dump(comments, file_path, ensure_ascii=False, indent=4)\n",
    "            \n",
    "        return file_path.name\n",
    "    \n",
    "    def load_comment_list(self, file_path : str, data_column : str = 'text') -> list:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            file_path (str): The path to the JSON file containing the list of dictionaries with comments.\n",
    "            data_column (str, optional): The column to extract from the JSON file. Defaults to 'text'.\n",
    "            \n",
    "        Returns:\n",
    "            list: A list of dictionaries containing the comments.\n",
    "        \"\"\"\n",
    "        data_list = []\n",
    "        if not os.path.isfile(file_path):\n",
    "            return []\n",
    "        else:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                comment_data = json.load(f)\n",
    "                for data in comment_data:\n",
    "                    data_list.append(data[data_column])\n",
    "            return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiktok_scraper = TitkTokCommentScraper()\n",
    "\n",
    "posts_url = [\n",
    "    \"https://www.tiktok.com/@burnxice/video/7390628837131914503\", \n",
    "    \"https://www.tiktok.com/@keemokazi/video/7430978142325509419\",\n",
    "    \"https://www.tiktok.com/@itsqcp/video/7429806435183217963\",    \n",
    "    \"https://www.tiktok.com/@fdontcare/video/7413091288263691553\",    \n",
    "    ]\n",
    "cursor = 0\n",
    "\n",
    "for post_url in posts_url:\n",
    "    comments_file = tiktok_scraper.get_comments(post_url, cursor)\n",
    "    # comments_list = tiktok_scraper.load_comment_list(comments_file, 'text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roberta Pre-Trained Model\n",
    "- Use a model trained from a large corpus of data\n",
    "- Transformer model accounts for the words but also the context related to other words.\n",
    "- Define a general sentiment for the data.\n",
    "\n",
    "Resources: https://www.youtube.com/watch?v=QpzMWQvxXWk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "def polarity_scores_roberta(text : str) -> dict:\n",
    "    \"\"\"\n",
    "    Analyzes the sentiment of a text using the Roberta model.\n",
    "    Args:\n",
    "        text (str): The text to analyze.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary containing the sentiment scores.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        encoded_text = tokenizer(text, return_tensors=\"pt\")\n",
    "        output = model(**encoded_text)\n",
    "        scores = output[0][0].detach().numpy()\n",
    "        scores = softmax(scores)\n",
    "        scores_dict = dict(zip(['negative', 'neutral', 'positive'], scores))\n",
    "        return scores_dict\n",
    "    except RuntimeError:\n",
    "        print('Unable to process the text')\n",
    "\n",
    "def create_dataframe(comments_list : list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a dataframe from a list of comments.\n",
    "    Args:\n",
    "        comments_list (list): A list of comments.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A dataframe containing the comments and their sentiment scores.\n",
    "    \"\"\"\n",
    "    comments_series = pd.Series(comments_list)\n",
    "    \n",
    "    sentiment_scores = comments_series.apply(polarity_scores_roberta)\n",
    "    sentiments = sentiment_scores.apply(lambda x: max(x, key=x.get))\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'comment': comments_list,\n",
    "        'sentiment': sentiments,\n",
    "        'negative': sentiment_scores.apply(lambda x: x['negative']),\n",
    "        'neutral': sentiment_scores.apply(lambda x: x['neutral']),\n",
    "        'positive': sentiment_scores.apply(lambda x: x['positive'])\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "def evaluate_general_sentiment(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Evaluates the general sentiment of a dataframe.\n",
    "    Args:\n",
    "        df (pd.DataFrame): A dataframe containing the comments and their sentiment scores.\n",
    "        \n",
    "    Returns:\n",
    "        str: The general sentiment of the dataframe.\n",
    "    \"\"\"\n",
    "    average_negative = df['negative'].sum()\n",
    "    average_neutral = df['neutral'].sum()\n",
    "    average_positive = df['positive'].sum()\n",
    "\n",
    "    if average_positive > average_neutral and average_positive > average_negative:\n",
    "        general_sentiment = 'positive'\n",
    "    elif average_negative > average_neutral and average_negative > average_positive:\n",
    "        general_sentiment = 'negative'\n",
    "    else:\n",
    "        general_sentiment = 'neutral'\n",
    "\n",
    "    return f'The general sentiment is: {general_sentiment}'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all json files in the folder\n",
    "import os\n",
    "\n",
    "tiktok_scraper = TitkTokCommentScraper()\n",
    "file_path = os.getcwd()\n",
    "comment_files = []\n",
    "\n",
    "for file in os.listdir(file_path):\n",
    "    if file.endswith(\".json\"):\n",
    "        comment_files.append(file)\n",
    "\n",
    "for file in comment_files:\n",
    "    comments_list = tiktok_scraper.load_comment_list(file, 'text')\n",
    "    df = create_dataframe(comments_list)\n",
    "    print(f\"general sentiment for {file}\")\n",
    "    print(evaluate_general_sentiment(df))\n",
    "    print(\"----------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Cloud\n",
    "- Re-arrange the data to use all comments from the videos\n",
    "- Use interpolation 'bilinear' for simplicity\n",
    "\n",
    "Resources: https://www.youtube.com/watch?v=X59oBuevKVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from wordcloud import STOPWORDS\n",
    "import string\n",
    "\n",
    "alphabet = list(string.ascii_lowercase[::-1])\n",
    "\n",
    "aditional_stopwords = [\"ur\", \"thats\", \"ok\", ] + alphabet + list(STOPWORDS)\n",
    "\n",
    "# word_cloud = WordCloud(width=800, height=600, background_color='white', stopwords=STOPWORDS).generate_from_frequencies(df['sentiment'].value_counts())\n",
    "word_cloud = WordCloud(width=800, height=600, background_color='black', max_words = 20, stopwords=aditional_stopwords).generate(df['comment'].str.cat(sep=' '))\n",
    "word_cloud.to_image()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
